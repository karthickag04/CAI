{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pdfplumber) (11.3.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python313\\site-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cryptography-45.0.6-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.1/5.6 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.9/5.6 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.5/5.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 2.2 MB/s  0:00:02\n",
      "Downloading cryptography-45.0.6-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.0/3.4 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.6/3.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.6/3.4 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.4 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 2.7 MB/s  0:00:01\n",
      "Downloading cffi-1.17.1-cp313-cp313-win_amd64.whl (182 kB)\n",
      "Downloading pypdfium2-4.30.0-py3-none-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.9 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.9 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.9 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/2.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.6/2.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 1.9 MB/s  0:00:01\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pypdfium2, pycparser, cffi, cryptography, pdfminer.six, pdfplumber\n",
      "\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ---------------------------------------- 0/6 [pypdfium2]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------ --------------------------------- 1/6 [pycparser]\n",
      "   ------------- -------------------------- 2/6 [cffi]\n",
      "   ------------- -------------------------- 2/6 [cffi]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------- ------------------- 3/6 [cryptography]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   -------------------------- ------------- 4/6 [pdfminer.six]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   --------------------------------- ------ 5/6 [pdfplumber]\n",
      "   ---------------------------------------- 6/6 [pdfplumber]\n",
      "\n",
      "Successfully installed cffi-1.17.1 cryptography-45.0.6 pdfminer.six-20250506 pdfplumber-0.11.7 pycparser-2.22 pypdfium2-4.30.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure NLTK corpora are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(text):\n",
    "    \"\"\"Extract name using Named Entity Recognition.\"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    print(sentences)\n",
    "    for sentence in sentences:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        print(tokens)\n",
    "        tags = nltk.pos_tag(tokens)\n",
    "        print(tags)\n",
    "        chunks = ne_chunk(tags)\n",
    "        print(chunks)\n",
    "        for chunk in chunks:\n",
    "            if isinstance(chunk, Tree) and chunk.label() == 'PERSON':\n",
    "                return \" \".join(c[0] for c in chunk)\n",
    "    return \"Not Found\"\n",
    "\n",
    "def extract_email(text):\n",
    "    \"\"\"Extract email using regex.\"\"\"\n",
    "    email_match = re.search(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', text)\n",
    "    print(email_match)\n",
    "    print(email_match.group(0))\n",
    "    return email_match.group(0) if email_match else \"Not Found\"\n",
    "\n",
    "def extract_qualification(text):\n",
    "    \"\"\"Extract qualifications by matching common degree terms.\"\"\"\n",
    "    qualifications = re.findall(r'\\b(B(?:\\.|achelor)?|M(?:\\.|aster)?|Ph\\.?D|Diploma|High School|HSC|UG|PG|CS|Engineering|Science)\\b', text, re.IGNORECASE)\n",
    "    print(qualifications)\n",
    "    return \", \".join(set(qualifications)) if qualifications else \"Not Found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_resume_details_nltk(file_path):\n",
    "    \"\"\"Extract details using pdfplumber and NLTK.\"\"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()  # text = text + page.extract_text() \n",
    "        print(text)\n",
    "    \n",
    "    name = extract_name(text)\n",
    "    print(name)\n",
    "    email = extract_email(text)\n",
    "    print(email)\n",
    "    qualification = extract_qualification(text)\n",
    "    print(qualification)\n",
    "    \n",
    "    print({\"Name\": name, \"Qualification\": qualification, \"Email\": email})\n",
    "    return {\"Name\": name, \"Qualification\": qualification, \"Email\": email}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['veera02.pdf', 'Resume01.pdf']\n",
      "[]\n",
      "VEERAPANDI M\n",
      "FULL STACK DEVELOPER\n",
      "mveerapandi018@gmail.com | +91 9345047948 | TRICHY\n",
      "SUMMARY\n",
      "Skilled in managing simple projects, while contributing effectively as a team member to more complex projects,\n",
      "proficient in programming using multiple software languages, with experience in developing, testing, and\n",
      "evaluating software solutions, adept at working with hardware infrastructure and network solutions to achieve\n",
      "client-specific goals and desired outcomes\n",
      "TECHNICAL SKILLS PERSONAL SKILLS\n",
      "UI  MYSQL  Project Management  Critical Thinking\n",
      "HTML &CSS  JAVA  Leadership  Multi tasker\n",
      "JAVASCRIPT  Problem-Solving  Team Collaboration\n",
      "EDUCATION\n",
      "Diploma in Computer Engineering 2018 -2022\n",
      "M.I.E.T. Polytechnic College, Trichy\n",
      "BE(Computer Science and Engineering) 2022 -2025\n",
      "pavendar bharathidasan college of engineering and technology\n",
      "COURESE\n",
      "FULL STACK DEVELOPMENT AT G-TEC COMPUTER EDUCATION,TRICHY SEP2024 -FEB2025\n",
      "I successfully completed a full-stack development course that offered practical experience with key web\n",
      "technologies This involved mastering front-end tools like HTML, CSS, and JavaScript frameworks, alongside gaining\n",
      "proficiency in back-end development with server-side programming and database management; I excel at crafting\n",
      "responsive user interfaces and building reliable, scalable applications from the ground up\n",
      "PROJECT\n",
      "Project Title: Male Fashion Ecommerce Website \n",
      "Technologies Used: HTML, CSS, JavaScript\n",
      "Developed a fully responsive Ecommerce website tailored to men's fashion, allowing users to browse, filter, and\n",
      "purchase clothing and accessories. The website was designed with a user-friendly interface to enhance the online\n",
      "shopping experience\n",
      "INTERNSHIP\n",
      "AI Development & Machine Learning at NRG Phoenix Technology India Pvt. Ltd.\n",
      "Contributed to AI and machine learning projects by assisting in model development, data preprocessing, and\n",
      "algorithm optimization. Gained hands-on experience with various ML frameworks to enhance predictive\n",
      "capabilities and system efficiency.\n",
      "LANGUAGES\n",
      "TAMI \n",
      "ENGLISH\n",
      "['VEERAPANDI M\\nFULL STACK DEVELOPER\\nmveerapandi018@gmail.com | +91 9345047948 | TRICHY\\nSUMMARY\\nSkilled in managing simple projects, while contributing effectively as a team member to more complex projects,\\nproficient in programming using multiple software languages, with experience in developing, testing, and\\nevaluating software solutions, adept at working with hardware infrastructure and network solutions to achieve\\nclient-specific goals and desired outcomes\\nTECHNICAL SKILLS PERSONAL SKILLS\\nUI  MYSQL  Project Management  Critical Thinking\\nHTML &CSS  JAVA  Leadership  Multi tasker\\nJAVASCRIPT  Problem-Solving  Team Collaboration\\nEDUCATION\\nDiploma in Computer Engineering 2018 -2022\\nM.I.E.T.', \"Polytechnic College, Trichy\\nBE(Computer Science and Engineering) 2022 -2025\\npavendar bharathidasan college of engineering and technology\\nCOURESE\\nFULL STACK DEVELOPMENT AT G-TEC COMPUTER EDUCATION,TRICHY SEP2024 -FEB2025\\nI successfully completed a full-stack development course that offered practical experience with key web\\ntechnologies This involved mastering front-end tools like HTML, CSS, and JavaScript frameworks, alongside gaining\\nproficiency in back-end development with server-side programming and database management; I excel at crafting\\nresponsive user interfaces and building reliable, scalable applications from the ground up\\nPROJECT\\nProject Title: Male Fashion Ecommerce Website\\u2028\\nTechnologies Used: HTML, CSS, JavaScript\\nDeveloped a fully responsive Ecommerce website tailored to men's fashion, allowing users to browse, filter, and\\npurchase clothing and accessories.\", 'The website was designed with a user-friendly interface to enhance the online\\nshopping experience\\nINTERNSHIP\\nAI Development & Machine Learning at NRG Phoenix Technology India Pvt.', 'Ltd.', 'Contributed to AI and machine learning projects by assisting in model development, data preprocessing, and\\nalgorithm optimization.', 'Gained hands-on experience with various ML frameworks to enhance predictive\\ncapabilities and system efficiency.', 'LANGUAGES\\nTAMI \\nENGLISH']\n",
      "['VEERAPANDI', 'M', 'FULL', 'STACK', 'DEVELOPER', 'mveerapandi018', '@', 'gmail.com', '|', '+91', '9345047948', '|', 'TRICHY', 'SUMMARY', 'Skilled', 'in', 'managing', 'simple', 'projects', ',', 'while', 'contributing', 'effectively', 'as', 'a', 'team', 'member', 'to', 'more', 'complex', 'projects', ',', 'proficient', 'in', 'programming', 'using', 'multiple', 'software', 'languages', ',', 'with', 'experience', 'in', 'developing', ',', 'testing', ',', 'and', 'evaluating', 'software', 'solutions', ',', 'adept', 'at', 'working', 'with', 'hardware', 'infrastructure', 'and', 'network', 'solutions', 'to', 'achieve', 'client-specific', 'goals', 'and', 'desired', 'outcomes', 'TECHNICAL', 'SKILLS', 'PERSONAL', 'SKILLS', 'UI', 'MYSQL', 'Project', 'Management', 'Critical', 'Thinking', 'HTML', '&', 'CSS', 'JAVA', 'Leadership', 'Multi', 'tasker', 'JAVASCRIPT', 'Problem-Solving', 'Team', 'Collaboration', 'EDUCATION', 'Diploma', 'in', 'Computer', 'Engineering', '2018', '-2022', 'M.I.E.T', '.']\n",
      "[('VEERAPANDI', 'NNP'), ('M', 'NNP'), ('FULL', 'NNP'), ('STACK', 'NNP'), ('DEVELOPER', 'NNP'), ('mveerapandi018', 'NN'), ('@', 'NNP'), ('gmail.com', 'NN'), ('|', 'NNP'), ('+91', 'VBZ'), ('9345047948', 'CD'), ('|', 'JJ'), ('TRICHY', 'NNP'), ('SUMMARY', 'NNP'), ('Skilled', 'VBD'), ('in', 'IN'), ('managing', 'VBG'), ('simple', 'JJ'), ('projects', 'NNS'), (',', ','), ('while', 'IN'), ('contributing', 'VBG'), ('effectively', 'RB'), ('as', 'IN'), ('a', 'DT'), ('team', 'NN'), ('member', 'NN'), ('to', 'TO'), ('more', 'RBR'), ('complex', 'JJ'), ('projects', 'NNS'), (',', ','), ('proficient', 'NN'), ('in', 'IN'), ('programming', 'VBG'), ('using', 'VBG'), ('multiple', 'JJ'), ('software', 'NN'), ('languages', 'NNS'), (',', ','), ('with', 'IN'), ('experience', 'NN'), ('in', 'IN'), ('developing', 'VBG'), (',', ','), ('testing', 'VBG'), (',', ','), ('and', 'CC'), ('evaluating', 'VBG'), ('software', 'NN'), ('solutions', 'NNS'), (',', ','), ('adept', 'NN'), ('at', 'IN'), ('working', 'VBG'), ('with', 'IN'), ('hardware', 'JJ'), ('infrastructure', 'NN'), ('and', 'CC'), ('network', 'NN'), ('solutions', 'NNS'), ('to', 'TO'), ('achieve', 'VB'), ('client-specific', 'JJ'), ('goals', 'NNS'), ('and', 'CC'), ('desired', 'VBN'), ('outcomes', 'NNS'), ('TECHNICAL', 'NNP'), ('SKILLS', 'NNP'), ('PERSONAL', 'NNP'), ('SKILLS', 'NNP'), ('UI', 'NNP'), ('MYSQL', 'NNP'), ('Project', 'NNP'), ('Management', 'NNP'), ('Critical', 'NNP'), ('Thinking', 'NNP'), ('HTML', 'NNP'), ('&', 'CC'), ('CSS', 'NNP'), ('JAVA', 'NNP'), ('Leadership', 'NNP'), ('Multi', 'NNP'), ('tasker', 'NN'), ('JAVASCRIPT', 'NNP'), ('Problem-Solving', 'NNP'), ('Team', 'NNP'), ('Collaboration', 'NNP'), ('EDUCATION', 'NNP'), ('Diploma', 'NNP'), ('in', 'IN'), ('Computer', 'NNP'), ('Engineering', 'NNP'), ('2018', 'CD'), ('-2022', 'NNP'), ('M.I.E.T', 'NNP'), ('.', '.')]\n",
      "(S\n",
      "  (ORGANIZATION VEERAPANDI/NNP)\n",
      "  M/NNP\n",
      "  FULL/NNP\n",
      "  STACK/NNP\n",
      "  DEVELOPER/NNP\n",
      "  mveerapandi018/NN\n",
      "  @/NNP\n",
      "  gmail.com/NN\n",
      "  |/NNP\n",
      "  +91/VBZ\n",
      "  9345047948/CD\n",
      "  |/JJ\n",
      "  (ORGANIZATION TRICHY/NNP)\n",
      "  SUMMARY/NNP\n",
      "  Skilled/VBD\n",
      "  in/IN\n",
      "  managing/VBG\n",
      "  simple/JJ\n",
      "  projects/NNS\n",
      "  ,/,\n",
      "  while/IN\n",
      "  contributing/VBG\n",
      "  effectively/RB\n",
      "  as/IN\n",
      "  a/DT\n",
      "  team/NN\n",
      "  member/NN\n",
      "  to/TO\n",
      "  more/RBR\n",
      "  complex/JJ\n",
      "  projects/NNS\n",
      "  ,/,\n",
      "  proficient/NN\n",
      "  in/IN\n",
      "  programming/VBG\n",
      "  using/VBG\n",
      "  multiple/JJ\n",
      "  software/NN\n",
      "  languages/NNS\n",
      "  ,/,\n",
      "  with/IN\n",
      "  experience/NN\n",
      "  in/IN\n",
      "  developing/VBG\n",
      "  ,/,\n",
      "  testing/VBG\n",
      "  ,/,\n",
      "  and/CC\n",
      "  evaluating/VBG\n",
      "  software/NN\n",
      "  solutions/NNS\n",
      "  ,/,\n",
      "  adept/NN\n",
      "  at/IN\n",
      "  working/VBG\n",
      "  with/IN\n",
      "  hardware/JJ\n",
      "  infrastructure/NN\n",
      "  and/CC\n",
      "  network/NN\n",
      "  solutions/NNS\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  client-specific/JJ\n",
      "  goals/NNS\n",
      "  and/CC\n",
      "  desired/VBN\n",
      "  outcomes/NNS\n",
      "  (ORGANIZATION TECHNICAL/NNP)\n",
      "  SKILLS/NNP\n",
      "  PERSONAL/NNP\n",
      "  SKILLS/NNP\n",
      "  UI/NNP\n",
      "  MYSQL/NNP\n",
      "  Project/NNP\n",
      "  Management/NNP\n",
      "  Critical/NNP\n",
      "  Thinking/NNP\n",
      "  HTML/NNP\n",
      "  &/CC\n",
      "  (ORGANIZATION CSS/NNP)\n",
      "  JAVA/NNP\n",
      "  Leadership/NNP\n",
      "  Multi/NNP\n",
      "  tasker/NN\n",
      "  (ORGANIZATION JAVASCRIPT/NNP)\n",
      "  Problem-Solving/NNP\n",
      "  Team/NNP\n",
      "  Collaboration/NNP\n",
      "  EDUCATION/NNP\n",
      "  Diploma/NNP\n",
      "  in/IN\n",
      "  (ORGANIZATION Computer/NNP)\n",
      "  Engineering/NNP\n",
      "  2018/CD\n",
      "  -2022/NNP\n",
      "  M.I.E.T/NNP\n",
      "  ./.)\n",
      "['Polytechnic', 'College', ',', 'Trichy', 'BE', '(', 'Computer', 'Science', 'and', 'Engineering', ')', '2022', '-2025', 'pavendar', 'bharathidasan', 'college', 'of', 'engineering', 'and', 'technology', 'COURESE', 'FULL', 'STACK', 'DEVELOPMENT', 'AT', 'G-TEC', 'COMPUTER', 'EDUCATION', ',', 'TRICHY', 'SEP2024', '-FEB2025', 'I', 'successfully', 'completed', 'a', 'full-stack', 'development', 'course', 'that', 'offered', 'practical', 'experience', 'with', 'key', 'web', 'technologies', 'This', 'involved', 'mastering', 'front-end', 'tools', 'like', 'HTML', ',', 'CSS', ',', 'and', 'JavaScript', 'frameworks', ',', 'alongside', 'gaining', 'proficiency', 'in', 'back-end', 'development', 'with', 'server-side', 'programming', 'and', 'database', 'management', ';', 'I', 'excel', 'at', 'crafting', 'responsive', 'user', 'interfaces', 'and', 'building', 'reliable', ',', 'scalable', 'applications', 'from', 'the', 'ground', 'up', 'PROJECT', 'Project', 'Title', ':', 'Male', 'Fashion', 'Ecommerce', 'Website', 'Technologies', 'Used', ':', 'HTML', ',', 'CSS', ',', 'JavaScript', 'Developed', 'a', 'fully', 'responsive', 'Ecommerce', 'website', 'tailored', 'to', 'men', \"'s\", 'fashion', ',', 'allowing', 'users', 'to', 'browse', ',', 'filter', ',', 'and', 'purchase', 'clothing', 'and', 'accessories', '.']\n",
      "[('Polytechnic', 'NNP'), ('College', 'NNP'), (',', ','), ('Trichy', 'NNP'), ('BE', 'NNP'), ('(', '('), ('Computer', 'NNP'), ('Science', 'NNP'), ('and', 'CC'), ('Engineering', 'NNP'), (')', ')'), ('2022', 'CD'), ('-2025', 'NNP'), ('pavendar', 'NN'), ('bharathidasan', 'JJ'), ('college', 'NN'), ('of', 'IN'), ('engineering', 'NN'), ('and', 'CC'), ('technology', 'NN'), ('COURESE', 'NNP'), ('FULL', 'NNP'), ('STACK', 'NNP'), ('DEVELOPMENT', 'NNP'), ('AT', 'NNP'), ('G-TEC', 'NNP'), ('COMPUTER', 'NNP'), ('EDUCATION', 'NNP'), (',', ','), ('TRICHY', 'NNP'), ('SEP2024', 'NNP'), ('-FEB2025', 'NNP'), ('I', 'PRP'), ('successfully', 'RB'), ('completed', 'VBD'), ('a', 'DT'), ('full-stack', 'JJ'), ('development', 'NN'), ('course', 'NN'), ('that', 'WDT'), ('offered', 'VBD'), ('practical', 'JJ'), ('experience', 'NN'), ('with', 'IN'), ('key', 'JJ'), ('web', 'NN'), ('technologies', 'NNS'), ('This', 'DT'), ('involved', 'JJ'), ('mastering', 'VBG'), ('front-end', 'JJ'), ('tools', 'NNS'), ('like', 'IN'), ('HTML', 'NNP'), (',', ','), ('CSS', 'NNP'), (',', ','), ('and', 'CC'), ('JavaScript', 'NNP'), ('frameworks', 'NNS'), (',', ','), ('alongside', 'RB'), ('gaining', 'VBG'), ('proficiency', 'NN'), ('in', 'IN'), ('back-end', 'JJ'), ('development', 'NN'), ('with', 'IN'), ('server-side', 'JJ'), ('programming', 'NN'), ('and', 'CC'), ('database', 'NN'), ('management', 'NN'), (';', ':'), ('I', 'PRP'), ('excel', 'VBP'), ('at', 'IN'), ('crafting', 'VBG'), ('responsive', 'JJ'), ('user', 'NN'), ('interfaces', 'NNS'), ('and', 'CC'), ('building', 'NN'), ('reliable', 'JJ'), (',', ','), ('scalable', 'JJ'), ('applications', 'NNS'), ('from', 'IN'), ('the', 'DT'), ('ground', 'NN'), ('up', 'RP'), ('PROJECT', 'NNP'), ('Project', 'NNP'), ('Title', 'NNP'), (':', ':'), ('Male', 'JJ'), ('Fashion', 'NNP'), ('Ecommerce', 'NNP'), ('Website', 'NNP'), ('Technologies', 'NNPS'), ('Used', 'VBD'), (':', ':'), ('HTML', 'NNP'), (',', ','), ('CSS', 'NNP'), (',', ','), ('JavaScript', 'NNP'), ('Developed', 'VBD'), ('a', 'DT'), ('fully', 'RB'), ('responsive', 'JJ'), ('Ecommerce', 'NNP'), ('website', 'NN'), ('tailored', 'VBD'), ('to', 'TO'), ('men', 'NNS'), (\"'s\", 'POS'), ('fashion', 'NN'), (',', ','), ('allowing', 'VBG'), ('users', 'NNS'), ('to', 'TO'), ('browse', 'VB'), (',', ','), ('filter', 'NN'), (',', ','), ('and', 'CC'), ('purchase', 'NN'), ('clothing', 'NN'), ('and', 'CC'), ('accessories', 'NNS'), ('.', '.')]\n",
      "(S\n",
      "  Polytechnic/NNP\n",
      "  College/NNP\n",
      "  ,/,\n",
      "  (PERSON Trichy/NNP BE/NNP)\n",
      "  (/(\n",
      "  (ORGANIZATION Computer/NNP Science/NNP)\n",
      "  and/CC\n",
      "  Engineering/NNP\n",
      "  )/)\n",
      "  2022/CD\n",
      "  -2025/NNP\n",
      "  pavendar/NN\n",
      "  bharathidasan/JJ\n",
      "  college/NN\n",
      "  of/IN\n",
      "  engineering/NN\n",
      "  and/CC\n",
      "  technology/NN\n",
      "  (ORGANIZATION COURESE/NNP)\n",
      "  FULL/NNP\n",
      "  STACK/NNP\n",
      "  DEVELOPMENT/NNP\n",
      "  AT/NNP\n",
      "  G-TEC/NNP\n",
      "  (ORGANIZATION COMPUTER/NNP)\n",
      "  EDUCATION/NNP\n",
      "  ,/,\n",
      "  (ORGANIZATION TRICHY/NNP)\n",
      "  SEP2024/NNP\n",
      "  -FEB2025/NNP\n",
      "  I/PRP\n",
      "  successfully/RB\n",
      "  completed/VBD\n",
      "  a/DT\n",
      "  full-stack/JJ\n",
      "  development/NN\n",
      "  course/NN\n",
      "  that/WDT\n",
      "  offered/VBD\n",
      "  practical/JJ\n",
      "  experience/NN\n",
      "  with/IN\n",
      "  key/JJ\n",
      "  web/NN\n",
      "  technologies/NNS\n",
      "  This/DT\n",
      "  involved/JJ\n",
      "  mastering/VBG\n",
      "  front-end/JJ\n",
      "  tools/NNS\n",
      "  like/IN\n",
      "  (ORGANIZATION HTML/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION CSS/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  (ORGANIZATION JavaScript/NNP)\n",
      "  frameworks/NNS\n",
      "  ,/,\n",
      "  alongside/RB\n",
      "  gaining/VBG\n",
      "  proficiency/NN\n",
      "  in/IN\n",
      "  back-end/JJ\n",
      "  development/NN\n",
      "  with/IN\n",
      "  server-side/JJ\n",
      "  programming/NN\n",
      "  and/CC\n",
      "  database/NN\n",
      "  management/NN\n",
      "  ;/:\n",
      "  I/PRP\n",
      "  excel/VBP\n",
      "  at/IN\n",
      "  crafting/VBG\n",
      "  responsive/JJ\n",
      "  user/NN\n",
      "  interfaces/NNS\n",
      "  and/CC\n",
      "  building/NN\n",
      "  reliable/JJ\n",
      "  ,/,\n",
      "  scalable/JJ\n",
      "  applications/NNS\n",
      "  from/IN\n",
      "  the/DT\n",
      "  ground/NN\n",
      "  up/RP\n",
      "  (ORGANIZATION PROJECT/NNP Project/NNP)\n",
      "  Title/NNP\n",
      "  :/:\n",
      "  (PERSON Male/JJ Fashion/NNP Ecommerce/NNP Website/NNP)\n",
      "  Technologies/NNPS\n",
      "  Used/VBD\n",
      "  :/:\n",
      "  HTML/NNP\n",
      "  ,/,\n",
      "  (ORGANIZATION CSS/NNP)\n",
      "  ,/,\n",
      "  (ORGANIZATION JavaScript/NNP)\n",
      "  Developed/VBD\n",
      "  a/DT\n",
      "  fully/RB\n",
      "  responsive/JJ\n",
      "  Ecommerce/NNP\n",
      "  website/NN\n",
      "  tailored/VBD\n",
      "  to/TO\n",
      "  men/NNS\n",
      "  's/POS\n",
      "  fashion/NN\n",
      "  ,/,\n",
      "  allowing/VBG\n",
      "  users/NNS\n",
      "  to/TO\n",
      "  browse/VB\n",
      "  ,/,\n",
      "  filter/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  purchase/NN\n",
      "  clothing/NN\n",
      "  and/CC\n",
      "  accessories/NNS\n",
      "  ./.)\n",
      "Trichy BE\n",
      "<re.Match object; span=(34, 58), match='mveerapandi018@gmail.com'>\n",
      "mveerapandi018@gmail.com\n",
      "mveerapandi018@gmail.com\n",
      "['M', 'Diploma', 'Engineering', 'M.', 'Science', 'Engineering', 'engineering']\n",
      "M., Engineering, Diploma, Science, engineering, M\n",
      "{'Name': 'Trichy BE', 'Qualification': 'M., Engineering, Diploma, Science, engineering, M', 'Email': 'mveerapandi018@gmail.com'}\n",
      "{'Name': 'Trichy BE', 'Qualification': 'M., Engineering, Diploma, Science, engineering, M', 'Email': 'mveerapandi018@gmail.com'}\n",
      "[{'Name': 'Trichy BE', 'Qualification': 'M., Engineering, Diploma, Science, engineering, M', 'Email': 'mveerapandi018@gmail.com'}]\n",
      "Dhanvand Srinivasan\n",
      "Ux|Ui Designer\n",
      "Education\n",
      "Hsc\n",
      "Daniel Thomas (2017 - 19)\n",
      "61%\n",
      "BSC - Cs\n",
      "SRM University (2019 - 22)\n",
      "First Class\n",
      "About Me\n",
      "Experience\n",
      "A Creative Ux|Ui Designer In Creating\n",
      "Intuitive And Visually Appealing User UX UI Designer Trainee\n",
      "Experiences.Passionate About Designing Phygitalz advisory and solutions (Apr24 - Jly24)\n",
      "Innovative Solutions. That Enhance User Oversaw all major Ai plants automation design & icons.\n",
      "Engagement And Satisfaction. Seeking A\n",
      "* OEE 4.0 * Traceabillty 4.0 * TLM 4.0\n",
      "Challenging Position Where I Can Apply My\n",
      "* PredictM 4.0 * ZeDQual 4.0 * Energy 4.0\n",
      "Expertise And Contribute To Creating\n",
      "Skills\n",
      "Exceptional Digital Products.\n",
      "* User Research\n",
      "Course\n",
      "* Persona Creation\n",
      "* Write User Stories\n",
      "Advanced Ux|Ui Designer\n",
      "* Prepare Scope Document\n",
      "* Create User Flow\n",
      "Jan - May (2023)\n",
      "* Build Information Architecture\n",
      "* Paper & Digital Prototypes\n",
      "Contact * Usability Testing\n",
      "* Ui Design\n",
      "9080146466\n",
      "Software Skills\n",
      "dhanvand333@gmail.com\n",
      "linkedin.com/in/dhanvand-srinivasan-65530b275\n",
      "Figma Invision Zeplin\n",
      "behance.net/dhanvand\n",
      "Prottapp Maze.Desgin\n",
      "['Dhanvand Srinivasan\\nUx|Ui Designer\\nEducation\\nHsc\\nDaniel Thomas (2017 - 19)\\n61%\\nBSC - Cs\\nSRM University (2019 - 22)\\nFirst Class\\nAbout Me\\nExperience\\nA Creative Ux|Ui Designer In Creating\\nIntuitive And Visually Appealing User UX UI Designer Trainee\\nExperiences.Passionate About Designing Phygitalz advisory and solutions (Apr24 - Jly24)\\nInnovative Solutions.', 'That Enhance User Oversaw all major Ai plants automation design & icons.', 'Engagement And Satisfaction.', 'Seeking A\\n* OEE 4.0 * Traceabillty 4.0 * TLM 4.0\\nChallenging Position Where I Can Apply My\\n* PredictM 4.0 * ZeDQual 4.0 * Energy 4.0\\nExpertise And Contribute To Creating\\nSkills\\nExceptional Digital Products.', '* User Research\\nCourse\\n* Persona Creation\\n* Write User Stories\\nAdvanced Ux|Ui Designer\\n* Prepare Scope Document\\n* Create User Flow\\nJan - May (2023)\\n* Build Information Architecture\\n* Paper & Digital Prototypes\\nContact * Usability Testing\\n* Ui Design\\n9080146466\\nSoftware Skills\\ndhanvand333@gmail.com\\nlinkedin.com/in/dhanvand-srinivasan-65530b275\\nFigma Invision Zeplin\\nbehance.net/dhanvand\\nProttapp Maze.Desgin']\n",
      "['Dhanvand', 'Srinivasan', 'Ux|Ui', 'Designer', 'Education', 'Hsc', 'Daniel', 'Thomas', '(', '2017', '-', '19', ')', '61', '%', 'BSC', '-', 'Cs', 'SRM', 'University', '(', '2019', '-', '22', ')', 'First', 'Class', 'About', 'Me', 'Experience', 'A', 'Creative', 'Ux|Ui', 'Designer', 'In', 'Creating', 'Intuitive', 'And', 'Visually', 'Appealing', 'User', 'UX', 'UI', 'Designer', 'Trainee', 'Experiences.Passionate', 'About', 'Designing', 'Phygitalz', 'advisory', 'and', 'solutions', '(', 'Apr24', '-', 'Jly24', ')', 'Innovative', 'Solutions', '.']\n",
      "[('Dhanvand', 'NNP'), ('Srinivasan', 'NNP'), ('Ux|Ui', 'NNP'), ('Designer', 'NNP'), ('Education', 'NNP'), ('Hsc', 'NNP'), ('Daniel', 'NNP'), ('Thomas', 'NNP'), ('(', '('), ('2017', 'CD'), ('-', ':'), ('19', 'CD'), (')', ')'), ('61', 'CD'), ('%', 'NN'), ('BSC', 'NNP'), ('-', ':'), ('Cs', 'NNP'), ('SRM', 'NNP'), ('University', 'NNP'), ('(', '('), ('2019', 'CD'), ('-', ':'), ('22', 'CD'), (')', ')'), ('First', 'NNP'), ('Class', 'NN'), ('About', 'IN'), ('Me', 'NNP'), ('Experience', 'NNP'), ('A', 'NNP'), ('Creative', 'NNP'), ('Ux|Ui', 'NNP'), ('Designer', 'NNP'), ('In', 'IN'), ('Creating', 'NNP'), ('Intuitive', 'NNP'), ('And', 'CC'), ('Visually', 'NNP'), ('Appealing', 'NNP'), ('User', 'NNP'), ('UX', 'NNP'), ('UI', 'NNP'), ('Designer', 'NNP'), ('Trainee', 'NNP'), ('Experiences.Passionate', 'NNP'), ('About', 'IN'), ('Designing', 'NNP'), ('Phygitalz', 'NNP'), ('advisory', 'NN'), ('and', 'CC'), ('solutions', 'NNS'), ('(', '('), ('Apr24', 'NNP'), ('-', ':'), ('Jly24', 'NN'), (')', ')'), ('Innovative', 'JJ'), ('Solutions', 'NNS'), ('.', '.')]\n",
      "(S\n",
      "  (GPE Dhanvand/NNP)\n",
      "  (ORGANIZATION Srinivasan/NNP)\n",
      "  Ux|Ui/NNP\n",
      "  Designer/NNP\n",
      "  Education/NNP\n",
      "  Hsc/NNP\n",
      "  (PERSON Daniel/NNP Thomas/NNP)\n",
      "  (/(\n",
      "  2017/CD\n",
      "  -/:\n",
      "  19/CD\n",
      "  )/)\n",
      "  61/CD\n",
      "  %/NN\n",
      "  (ORGANIZATION BSC/NNP)\n",
      "  -/:\n",
      "  (PERSON Cs/NNP SRM/NNP University/NNP)\n",
      "  (/(\n",
      "  2019/CD\n",
      "  -/:\n",
      "  22/CD\n",
      "  )/)\n",
      "  First/NNP\n",
      "  Class/NN\n",
      "  About/IN\n",
      "  (PERSON Me/NNP Experience/NNP)\n",
      "  A/NNP\n",
      "  Creative/NNP\n",
      "  Ux|Ui/NNP\n",
      "  Designer/NNP\n",
      "  In/IN\n",
      "  (GPE Creating/NNP)\n",
      "  Intuitive/NNP\n",
      "  And/CC\n",
      "  (PERSON\n",
      "    Visually/NNP\n",
      "    Appealing/NNP\n",
      "    User/NNP\n",
      "    UX/NNP\n",
      "    UI/NNP\n",
      "    Designer/NNP\n",
      "    Trainee/NNP)\n",
      "  Experiences.Passionate/NNP\n",
      "  About/IN\n",
      "  Designing/NNP\n",
      "  Phygitalz/NNP\n",
      "  advisory/NN\n",
      "  and/CC\n",
      "  solutions/NNS\n",
      "  (/(\n",
      "  (ORGANIZATION Apr24/NNP)\n",
      "  -/:\n",
      "  (GPE Jly24/NN)\n",
      "  )/)\n",
      "  Innovative/JJ\n",
      "  Solutions/NNS\n",
      "  ./.)\n",
      "Daniel Thomas\n",
      "<re.Match object; span=(942, 963), match='dhanvand333@gmail.com'>\n",
      "dhanvand333@gmail.com\n",
      "dhanvand333@gmail.com\n",
      "['Hsc', 'Cs']\n",
      "Cs, Hsc\n",
      "{'Name': 'Daniel Thomas', 'Qualification': 'Cs, Hsc', 'Email': 'dhanvand333@gmail.com'}\n",
      "{'Name': 'Daniel Thomas', 'Qualification': 'Cs, Hsc', 'Email': 'dhanvand333@gmail.com'}\n",
      "[{'Name': 'Trichy BE', 'Qualification': 'M., Engineering, Diploma, Science, engineering, M', 'Email': 'mveerapandi018@gmail.com'}, {'Name': 'Daniel Thomas', 'Qualification': 'Cs, Hsc', 'Email': 'dhanvand333@gmail.com'}]\n",
      "[{'Name': 'Trichy BE', 'Qualification': 'M., Engineering, Diploma, Science, engineering, M', 'Email': 'mveerapandi018@gmail.com'}, {'Name': 'Daniel Thomas', 'Qualification': 'Cs, Hsc', 'Email': 'dhanvand333@gmail.com'}]\n",
      "            Name                                      Qualification  \\\n",
      "0      Trichy BE  M., Engineering, Diploma, Science, engineering, M   \n",
      "1  Daniel Thomas                                            Cs, Hsc   \n",
      "\n",
      "                      Email  \n",
      "0  mveerapandi018@gmail.com  \n",
      "1     dhanvand333@gmail.com  \n",
      "Data saved to extracted_resume_data_nltk.csv\n"
     ]
    }
   ],
   "source": [
    "# Process all resumes\n",
    "resume_files = [\"veera02.pdf\",\"Resume01.pdf\"]  # List of resume file paths\n",
    "resume_data = []\n",
    "print(resume_files)\n",
    "print(resume_data)\n",
    "\n",
    "for file in resume_files:\n",
    "    details = extract_resume_details_nltk(file)\n",
    "    print(details)\n",
    "    resume_data.append(details)\n",
    "    print(resume_data)\n",
    "\n",
    "print(resume_data)\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(resume_data)\n",
    "print(df)\n",
    "output_path = \"extracted_resume_data_nltk.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete code on resume name, email extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted and saved to all_resumes_extracted_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Ensure NLTK corpora are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "def extract_name(text):\n",
    "    \"\"\"Extract name using Named Entity Recognition.\"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        tags = nltk.pos_tag(tokens)\n",
    "        chunks = ne_chunk(tags)\n",
    "        for chunk in chunks:\n",
    "            if isinstance(chunk, Tree) and chunk.label() == 'PERSON':\n",
    "                return \" \".join(c[0] for c in chunk)\n",
    "    return \"Not Found\"\n",
    "\n",
    "def extract_email(text):\n",
    "    \"\"\"Extract email using regex.\"\"\"\n",
    "    email_match = re.search(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', text)\n",
    "    return email_match.group(0) if email_match else \"Not Found\"\n",
    "\n",
    "def extract_qualification(text):\n",
    "    \"\"\"Extract qualifications by matching common degree terms.\"\"\"\n",
    "    qualifications = re.findall(\n",
    "        r'\\b(B(?:\\.|achelor)?|M(?:\\.|aster)?|Ph\\.?D|Diploma|High School|HSC|UG|PG|CS|Engineering|Science)\\b',\n",
    "        text, re.IGNORECASE\n",
    "    )\n",
    "    return \", \".join(set(qualifications)) if qualifications else \"Not Found\"\n",
    "\n",
    "def extract_resume_details_nltk(file_path):\n",
    "    \"\"\"Extract details from a resume using pdfplumber and NLTK.\"\"\"\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "    \n",
    "    return {\n",
    "        \"FileName\": file_path,\n",
    "        \"Name\": extract_name(text),\n",
    "        \"Email\": extract_email(text),\n",
    "        \"Qualification\": extract_qualification(text)\n",
    "    }\n",
    "\n",
    "# === PROCESSING MULTIPLE PDFS ===\n",
    "resume_files = [\"veera02.pdf\", \"resume01.pdf\", \"resume02.pdf\"]  # Add all your resume PDF paths here\n",
    "\n",
    "resume_data = [extract_resume_details_nltk(file) for file in resume_files]\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(resume_data)\n",
    "output_path = \"all_resumes_extracted_data.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data extracted and saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
